{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51533450",
   "metadata": {},
   "source": [
    "#Week 3 MiniProject\n",
    "\n",
    "#Description\n",
    "\n",
    "In this project we are going to build a Convolutional Neural Network in an attempt to identify metastatic cancer in small image patches taken from digital pathology scans.\n",
    "\n",
    "This dataset of training images is made up of 220,000 images, each being 96x96 pixels:{\"shape\": [96, 96, 3]}.\n",
    "\n",
    " The 3 refers to the number of color channels (R,G,B)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d21d22",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "374dbafb",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis\n",
    "\n",
    "Given the sheer size of the data and the amount of time it takes to train a neural network, the first thing I thought about was finding out a way to randomly select a subset of these images to save time as this is just a weekly mini-project.\n",
    "\n",
    "Below is my code for splitting up the training data in a fair way.\n",
    "This took about 5 minutes to run. Tallyho!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "069fde08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied and converted 50000 images to C:/Users/diego/GradSchool/DeepLearningIntro/WeekThree/project as JPGs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "image_folder = 'C:/Users/diego/GradSchool/DeepLearningIntro/WeekThree/train'\n",
    "output_folder = 'C:/Users/diego/GradSchool/DeepLearningIntro/WeekThree/project'\n",
    "sample_size = 50000\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "all_images = os.listdir(image_folder)\n",
    "sampled_images = random.sample(all_images, sample_size)\n",
    "\n",
    "for img_name in sampled_images:\n",
    "    src_path = os.path.join(image_folder, img_name)\n",
    "    dst_name = os.path.splitext(img_name)[0] + '.jpg'\n",
    "    dst_path = os.path.join(output_folder, dst_name)\n",
    "    \n",
    "    try:\n",
    "        with Image.open(src_path) as img:\n",
    "            rgb_img = img.convert('RGB')  # Convert in case it's grayscale or RGBA\n",
    "            rgb_img.save(dst_path, 'JPEG')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_name}: {e}\")\n",
    "\n",
    "print(f\"Copied and converted {len(sampled_images)} images to {output_folder} as JPGs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad284ee2",
   "metadata": {},
   "source": [
    "Now I have less images to work with. Cool. However, now my training labels CSV has 170k records that I do not need. \n",
    "Let's shave that down a bit now. Watch out for the file extension name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89fd636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from PIL import Image\n",
    "output_folder = 'C:/Users/diego/GradSchool/DeepLearningIntro/WeekThree/project'\n",
    "sampled_filenames = {filename.replace('.jpg', '') for filename in os.listdir(output_folder)}\n",
    "\n",
    "labels_df = pd.read_csv('train_labels.csv')\n",
    "filter_labels_df = labels_df[labels_df['id'].isin(sampled_filenames)]\n",
    "\n",
    "filter_labels_df.to_csv('labels_50k.csv',index = False)\n",
    "\n",
    "\n",
    "labels_df = pd.read_csv('labels_50k.csv')\n",
    "\n",
    "source_folder = 'C:/Users/diego/GradSchool/DeepLearningIntro/WeekThree/project'\n",
    "output_base = 'C:/Users/diego/GradSchool/DeepLearningIntro/WeekThree/project_filter'\n",
    "\n",
    "# Make class folders if they don't exist\n",
    "os.makedirs(os.path.join(output_base, '0'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_base, '1'), exist_ok=True)\n",
    "\n",
    "for _, row in labels_df.iterrows():\n",
    "    filename = row['id'] + '.jpg'\n",
    "    label = str(row['label'])\n",
    "    src_path = os.path.join(source_folder, filename)\n",
    "    dest_path = os.path.join(output_base, label, filename)\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.move(src_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec681ce",
   "metadata": {},
   "source": [
    "Model Architectures to Consider\n",
    "\n",
    "This is highly dependent on the amount of images I plan on including to train the neural network in the model.\n",
    "\n",
    "1. Simple Custom CNN \n",
    "\n",
    "Would essentially be working as follows:\n",
    "\n",
    "2-3 convolution layers, increasing the filters as the layers go on.\n",
    "\n",
    "Convolution -> ReLU -> MaxPool -> Convolution ->ReLU -> MaxPool -> Flatten -> Dense -> Sigmoid\n",
    "\n",
    "2. Pretrained Architectures\n",
    "\n",
    "I think the best pretrained architecture would be ResNet 34.\n",
    "\n",
    "My first attempt will be using a simple custom CNN.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56a83561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing import image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0d9885",
   "metadata": {},
   "source": [
    "Now its time to combine the model and our filtered dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebd9145b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 files belonging to 2 classes.\n",
      "Using 40000 files for training.\n",
      "Found 50000 files belonging to 2 classes.\n",
      "Using 10000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    'C:/Users/diego/GradSchool/DeepLearningIntro/WeekThree/project_filter',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=(96, 96),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    'C:/Users/diego/GradSchool/DeepLearningIntro/WeekThree/project_filter',\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=(96, 96),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "134ed2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">819,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m94\u001b[0m, \u001b[38;5;34m94\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m92\u001b[0m, \u001b[38;5;34m92\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m819,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">949,505</span> (3.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m949,505\u001b[0m (3.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">949,505</span> (3.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m949,505\u001b[0m (3.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation ='relu',input_shape = (96,96,3)))\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = keras.losses.binary_crossentropy, optimizer = 'adam',metrics =['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acbc6c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 183ms/step - accuracy: 0.7018 - loss: 2.3245 - val_accuracy: 0.8010 - val_loss: 0.4413\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 172ms/step - accuracy: 0.7887 - loss: 0.4798 - val_accuracy: 0.7856 - val_loss: 0.4634\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 178ms/step - accuracy: 0.7990 - loss: 0.4640 - val_accuracy: 0.8132 - val_loss: 0.4276\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 173ms/step - accuracy: 0.7917 - loss: 0.4631 - val_accuracy: 0.8072 - val_loss: 0.4358\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 174ms/step - accuracy: 0.8056 - loss: 0.4495 - val_accuracy: 0.8263 - val_loss: 0.4024\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 183ms/step - accuracy: 0.8179 - loss: 0.4219 - val_accuracy: 0.8410 - val_loss: 0.3775\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 169ms/step - accuracy: 0.8195 - loss: 0.4111 - val_accuracy: 0.8435 - val_loss: 0.3752\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 178ms/step - accuracy: 0.8314 - loss: 0.3926 - val_accuracy: 0.8373 - val_loss: 0.4212\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 172ms/step - accuracy: 0.8248 - loss: 0.3995 - val_accuracy: 0.8421 - val_loss: 0.3631\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 176ms/step - accuracy: 0.8413 - loss: 0.3770 - val_accuracy: 0.8143 - val_loss: 0.3922\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae71c06",
   "metadata": {},
   "source": [
    "1st Model Evaluation:\n",
    "\n",
    "Training accuracy increased from 70 to 84 percent. Validation accuracy reached 84 percent at its best. Training loss steadily decreased. \n",
    "\n",
    "No major overfitting noticed but validation accuracy plateaus after Epoch 6. There's a slight gap between training accuracy and validation accuracy as well.\n",
    "\n",
    "Let's try reducing our learning rate after a few epochs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd32c7c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e358411",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0607df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 176ms/step - accuracy: 0.8355 - loss: 0.3808 - val_accuracy: 0.8610 - val_loss: 0.3553 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 167ms/step - accuracy: 0.8434 - loss: 0.3636 - val_accuracy: 0.8529 - val_loss: 0.3368 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 170ms/step - accuracy: 0.8447 - loss: 0.3619 - val_accuracy: 0.8451 - val_loss: 0.3508 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8464 - loss: 0.3609\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 172ms/step - accuracy: 0.8464 - loss: 0.3609 - val_accuracy: 0.8590 - val_loss: 0.3571 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 169ms/step - accuracy: 0.8579 - loss: 0.3315 - val_accuracy: 0.8794 - val_loss: 0.3242 - learning_rate: 5.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 169ms/step - accuracy: 0.8660 - loss: 0.3206 - val_accuracy: 0.8823 - val_loss: 0.3319 - learning_rate: 5.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 169ms/step - accuracy: 0.8717 - loss: 0.3116 - val_accuracy: 0.8753 - val_loss: 0.3186 - learning_rate: 5.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 172ms/step - accuracy: 0.8693 - loss: 0.3072 - val_accuracy: 0.8820 - val_loss: 0.2963 - learning_rate: 5.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 170ms/step - accuracy: 0.8711 - loss: 0.3063 - val_accuracy: 0.8881 - val_loss: 0.3112 - learning_rate: 5.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.8719 - loss: 0.3029\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 178ms/step - accuracy: 0.8719 - loss: 0.3029 - val_accuracy: 0.8787 - val_loss: 0.3433 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=10,\n",
    "    callbacks = lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb257b6e",
   "metadata": {},
   "source": [
    "Accuracy improves from 84 to 88 percent - a large improvement over my first run through! The Learning rate got reduced twice, once at epoch 4 and again at epoch 10. \n",
    "Validation accuracy stayed more or less the same throughout, and the loss shows better convergence than the previous run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67efc6fe",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "My model performed pretty well in the first run and I got some pretty good improvements by adjusting the learning rate when accuracy was starting to plateau. \n",
    "\n",
    "Improvements I could try in the future would include Early Stopping to prevent unnecessary epochs after validation loss starts to spiral.\n",
    "\n",
    "I could also consider fine-tuning a pretrained model like mentioned earlier in this notebook - specifically ResNet 34 given the number of images I am training on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6747e9b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a313883",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
